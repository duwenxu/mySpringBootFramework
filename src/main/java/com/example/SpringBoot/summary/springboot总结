SpringBoot学习记录
1.	日期：02.22
1.	AOP无法切入同类调用的问题
问题：即在本类中调用同类的方法时无法使用增强
原因：https://blog.csdn.net/u012385190/article/details/82119928
在greetTo()方法里面直接调用serverTo(……)方法，这里还隐含一个关键字，那就是this，实际上这里调用是这样的：this.serverTo(),this是当前对象。而调用greetTo()是的对象是被代理的，在代理对象中执行增强后，通过invoke，用实际Waiter对象来调用greetTo()方法执行业务逻辑。在业务逻辑内又调用了serverTo(……)方法，调用的对象是当前对象，当前对象是Waiter，问题就出在这里，因为要想用执行serverTo方法的增强，必须用代理对象执行，但是此时却直接用Waiter对象调用，绕过了代理对象增强的部分，也就是说代理增强部分失效。
关键：调用本类方法时，默认的会有this.method()，相当于是本类直接调用方法，而不是通过代理调用，自然就不会被增强
		解决方法：在调用的方法中获取本类的代理对象强转后再调用方法
Java实现：(service)AopContext.currentProxy().method()
Kotlin实现：
val mySelfProxy = currentProxy() as KTPublicServiceImpl
return mySelfProxy.getAuth(clientId,clientSecret)

2.	@Cached注解
	在spring环境下，使用@Cached注解可以为一个方法添加缓存，@CacheUpdate用于更新缓存，@CacheInvalidate用于移除缓存元素。
	JetCache通过Spring AOP生成代理，来支持缓存功能注解可以加在接口上也可以加在类上，加注解的类必须是一个spring bean
	@CacheUpdate和@CacheInvalidate的name和area属性必须和@Cached相同，name属性还会用做cache的key前缀。
	@CacheUpdate和@CacheInvalidate的时候，相关的缓存操作可能会失败（比如网络IO错误），所以指定缓存的超时时间是非常重要的

JetCache主要通过@Cached和@CreateCache实现缓存
	@Cached是在接口方法或者类方法上添加缓存，一般以参数为key，以返回值为value存入缓存中（创建缓存方法）
	@Cached调用原理：系统调用该接口方法时检测到@Cached标签，首先会根据key去缓存中调用get方法获取value值，如果存在value值则直接将值返回，如果不存在key，则会执行被@Cached标记的接口或方法得到结果，并自动调用get方法将返回值存入缓存中。
	@CreateCache是直接创建一个缓存实例，然后调用put(T key， T value)、get(T key)等方法实现缓存。（创建缓存实例）
配置方法：
1.	在@SpringBootApplication注释的全局配置文件中开启缓存配置

@EnableMethodCache(basePackages = ["com.waytogalaxy.display"]) //设置缓存扫描地址
@EnableCreateCacheAnnotation  //缓存 激活@CreateCache

2.	配置JetCacheConfig类，激活@CreateCache和@Cached注解。
@Value注解,在属性名上添加该注解：
可以使用@Value 来读取application配置文件中的量   两种方式
① ${ property : default_value }    注意：kotlin里$有其表示含义(字符串表达式中)，所以在这里要加\转义
即 kotlin中   \${ property : default_value }
② #{ obj.property? :default_value }
第一个注入的是外部配置文件对应的property，第二个则是SpEL表达式对应的内容
@Configuration
@EnableMethodCache(basePackages = ["com.company.mypackage"])
@EnableCreateCacheAnnotation
@Configuration的使用：https://www.cnblogs.com/duanxz/p/7493276.html
@Cached的属性值说明：
	https://github.com/alibaba/jetcache/wiki/MethodCache_CN

3.	Rest返回状态信息 ResultApi
	使用SpringBoot编写接口的时候，最好是返回一个统一格式的JSON，该格式包含错误码，附带信息，以及携带的数据。这样前端在解析的时候就能统一解析，同时携带错误码可以更加容易的排查错误
2.	日期：02.27
1.	Controller中传入PrintWriter参数后，XSSFWorkbook.write(OutputStream)报错 错误信息：WRITER
2.	三种代理方式
JDK中的动态代理（JDK代理，接口代理）是通过反射类Proxy以及InvocationHandler回调接口实现的

3.	Kotlin中反射的使用
	java中获取Class的方法有
1、Class c = person.getClass(); //对象获取
2、Class cc =Person.class;//类获取
	Kotlin中：
//对象获取
person.javaClass    // javaClass
person::class.java // javaClass
//类获取
Person::class  // kClass
 person.javaClass.kotlin  // kClass
(Person::class as Any).javaClass  // javaClass
Person::class.java   // javaClass
	Kotlin与Java获取的Class两者的区别
kotlin中的Class与Java不同，kotlin中有一个自己的Class叫做KClass，person::class 和Person::class都是获取kotlin的KClass，所以println(person::class == Person::class) 为true。
我们可以从kotlin的KClass获取到java的Class,person::class.java就是如此，先获取到kotlin的KClass然后再获取javaClass。
object/class->kClass->Class
同样也可以通过java的Class获取kotlin的KClass，person.javaClass.kotlin就是先获取javaClass然后再获取kotlin的KClass
object/class->Class->KClass
4.	SpringSecurty
3.	Kotlin
1.	mapTo()
mapTo()方法   将给定的变换函数应用于原始数组的每个元素，并将结果附加到给定目标
2.	重要关键字
Let:
3.	高阶函数
3.1 fold 函数
计算集合累积值。
assertEquals(25, list.fold(4) { total, next -> total + next })
fold 函数有两个参数：initial 和 operation。
其中 initial 为初始值，operation 为一个高阶函数，这个函数有两个参数 R 和 T 并返回 R。
flod 函数会在所有集合元素上调用 operation 函数，在第一次调用的时候， R 值为 initial， T 为第一个集合元素，返回值作为下次调用 operation 的 R 参数，而 下一个集合元素为下一次 operation 调用的 T 参数，依次来遍历集合。
所以上面示例代码中实现的功能是，使用初始值 4 来计算 lsit 集合中所有元素加上 4 的和。
3.2	maxBy 函数
迭代器均可调用
例：获取map中的最大value所对应的key值
Map . entries . maxBy {it . value}?.key
3.3	Kotlin高阶函数使用
cacheObj.subscriptCache[user.websocketName()].second.subscriptions.removeAll { cacheObj -> msg.subscriptions.any { it.pageId == cacheObj.pageId } }
removeAll(): 删除所有满足条件匹配的项
4.	Redis
1.	命令行使用redis
进入redis所在的目录后
启动redis服务：redis-server.exe redis.windows.conf（不能够关闭）
连接redis服务器： redis-cli.exe -h 127.0.0.1 -p 6379
设置键值对及取出：set myKey abc      get mykey


2.	Jsonnull类型
a.	默认的Json()转换中（使用Gson()）转换策略为: 忽略空值，不对空值进行Json序列化
fun Any.toJson() = Gson().toJson(this)
fun Any.toSerialNullJson()=GsonBuilder().serializeNulls().create().toJson(this)
fun Any.toJsonObj() = Gson().toJsonTree(this).asJsonObject
/**
 * 保留空值的Json序列化方式
 */
fun Any.toSerialNullJsonObj()=GsonBuilder().serializeNulls().create().toJsonTree(this).asJsonObject
想要保留空值时只需要改变转换策略，如上
b . 转换后的空值类型为 Jsonnull，不同于一般的java中的null,也不是字符串“null”
判断：可以用JsonElement.isJsonNull()判断是否为该类型
	转换：JsonElement.getAsJsonNull()
5.	Linux
5.1换源  ：更换CentOS7的下载源为阿里云
一、安装epel安装
epel是个好东西，不过国外的速度实在是不能忍受。所以 有了这篇文章。
1、 首先卸载以前装的epel以免影响
rpm -e epel-release
2、 下载阿里提供的epel
wget -P /etc/yum.repos.d/ http://mirrors.aliyun.com/repo/epel-7.repo
3、yum clean all
4、yum makecache
好了，现在你要装epel源的软件的时候 不再慢吞吞了。
或者直接安装
rpm -ivh http://mirrors.aliyun.com/epel/epel-release-latest-7.noarch.rpm
二、Centos光盘的库
	1、备份
mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
	2、下载新的CentOS-Base.repo 到/etc/yum.repos.d/
CentOS 5
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo
CentOS 6
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo
CentOS 7
wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
	3、之后运行yum makecache生成缓存
5.2	安装Kafka

指令：
docker run -d --name kafka \
--publish 9092:9092 \
--env KAFKA_BROKER_ID=0 \
--env KAFKA_ZOOKEEPER_CONNECT=192.168.255.128:2181 \
--env KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.255.128:9092 \
--env KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -t wurstmeister/kafka

docker run -d --name kafka1 -p 9092:9092 --env KAFKA_ADVERTISED_HOST_NAME=localhost -e KAFKA_ZOOKEEPER_CONNECT=192.168.255:2181 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.255.219:9092 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092 -e KAFKA_HEAP_OPTS="-Xmx256M -Xms128M" --net=host wurstmeister/kafka

6.Kafka
1.	序列化和反序列化
2.

7.jetCache

8.记一次  synchronized 同步的应用
    场景：后端根据前端推送的订阅消息进行删除页面操作时
         订阅页面的类型： 增   删(删除 当前的并且 切换 到删除当前后的第一个)   切换
         分别对应的页面操作：从用户的订阅消息缓存中  添加  删除   切换（先删除再添加）
    问题产生原因：
        删除页面时 相当于同时有  删除和切换操作，即会同时发送两次 页面订阅
        处理页面订阅的执行方式并不是单线程的，所以当两个操作同时进行时，都对 用户的缓存进行了操作，导致执行根据下标删除页面订阅缓存的过程中发生了 角标越界等异常
    解决：
        在进行删除操作时对用户的订阅缓存信息加锁，保证在一次删除过程中获取到的缓存信息不变

9.HashMap数据结构分析比较：
    作用:存放键值对数据，是基于哈希表的Map接口实现，是常用的Java集合之一
    1.8前后的主要变化：
        JDK1.8 之前 HashMap 由 数组+链表 组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）.
            拉链法：  链表解决hash冲突原理：
                        链表数组即 数组中每一格(或者每个元素即为一个链表)，当遇到hash冲突时，将冲突的值加入到链表尾部即可。
        JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间
                (TreeMap和TreeSet的底层也用到了红黑树)

    底层数据结构分析：
        1.8之前：HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列
            如何得到元素存放位置： HashMap通过 key 的 hashCode 经过扰动函数(HashMap 的 hash 方法)处理过后得到 hash 值，然后通过 (n - 1) & hash 判断当前元素存放的位置（这里的 n 指的是数组的长度）
                注：hash函数
                static final int hash(Object key) {
                        int h;
                        // key.hashCode()：返回散列值也就是hashcode，该方法为native方法，调用底层库的方法
                        // ^ ：按位异或
                        // >>>:无符号右移，忽略符号位，空位都以0补齐
                        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
                    }

    HashMap 类的主要属性：
        public class HashMap<K,V> extends AbstractMap<K,V> implements Map<K,V>, Cloneable, Serializable {
            // 序列号
            private static final long serialVersionUID = 362498820763181265L;
            // 默认的初始容量是16
            static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;
            // 最大容量
            static final int MAXIMUM_CAPACITY = 1 << 30;
            // 默认的填充因子 0.75
            static final float DEFAULT_LOAD_FACTOR = 0.75f;
            // 当桶(bucket)上的结点数大于这个值时会转成红黑树
            static final int TREEIFY_THRESHOLD = 8;
                关于为什么是8的解释：
                        根据泊松分布结合填充因子为0.75来看
                        对于HashMap.table[].length的空间来说，放入0.75*length个数据，某一个bin中放入节点数量的概率情况如上图注释中给出的数据（表示数组某一个下标存放数据数量为0~8时的概率情况）
                             * 0:    0.60653066
                             * 1:    0.30326533
                             * 2:    0.07581633
                             * 3:    0.01263606
                             * 4:    0.00157952
                             * 5:    0.00015795
                             * 6:    0.00001316
                             * 7:    0.00000094
                             * 8:    0.00000006
                        对于HashMap table[]中任意一个bin(即table中的链表元素)上节点个数>=8 是小概率事件，即0.00000006，此时将会从Node转化为TreeNode  链表-->红黑树

            // 当桶(bucket)上的结点数小于这个值时树转链表
            static final int UNTREEIFY_THRESHOLD = 6;
            // 桶中结构转化为红黑树对应的table的最小大小
            static final int MIN_TREEIFY_CAPACITY = 64;
            // 存储元素的数组，总是2的幂次倍
            transient Node<k,v>[] table;
                关于HashMap的长度为什么总是2的幂次方：
                    tableSizeFor() 方法保证了容量总是2次幂
                    Hash值的范围:有符号整数的范围   -Integer.MAX_VALUE+1~Integer.MAX_VALUE
                                类似的： Byte范围 -128~127   1字节 8位
                    为什么：为了减少碰撞，保证HashMap存取高效，需要把数据尽量均匀的分布。因为Hash值的范围(即为有符号整数的范围)过大不能直接作为数组使用，需要对其长度取余hash%length
                            而  取余操作中如果除数是2的幂次方则等价于和其除数减一的&(按位与)操作，即当length是2的次幂时， hash%length==hash&(length-1)
                            且 采用二进制的按位与&操作相对于%运算可以提高效率，所以总采用HashMap长度为2的幂次方，用 hash&(n-1)(n代表数组长度)来计算数组下标
            // 存放具体元素的集
            transient Set<map.entry<k,v>> entrySet;
            // 存放元素的个数，注意这个不等于数组的长度。
            transient int size;
            // 每次扩容和更改map结构的计数器
            transient int modCount;
            // 临界值
            int threshold;
            // 加载因子
            final float loadFactor;
        }

        关于几个常见的参数：
            1. loadFactor加载因子：控制数组存放数据的疏密程度  默认值：0.75
                为什么是0.75：
                    太大：会导致 1.查找元素的效率降低 2.增加插入元素时的Hash冲突(Hash碰撞)
                    太小：数组空间的浪费，利用率降低，发生更多次数的reSize
                    0.75: 仅仅是一个在时间上和空间上的折衷选择。本质还是时间与空间的平衡。
            2. threshold 是否扩容的临界值，由默认容量和填充因子决定
                当实际大小(容量*填充因子)超过临界值时，会进行扩容   则默认容量为16，填充因子0.75时，默认的扩容长度为12

    put方法的原码分析：
         1.8:(其实是调用了putVal方法)
            ①如果定位到的 数组位置 没有元素 就直接插入。
            ②如果定位到的 数组位置 有元素
                                    就和要插入的key比较
                                        如果key相同就直接覆盖
                                        如果key不相同，就判断p是否是一个树节点
                                            如果是就调用e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key,value)将元素添加进入---红黑树插入
                                            如果不是就遍历链表插入(插入的是链表尾部)。---尾插法
         1.7：
            ①如果定位到的数组位置没有元素 就直接插入。
            ②如果定位到的数组位置有元素，遍历以这个元素为头结点的链表，依次和插入的key比较，如果key相同就直接覆盖，不同就采用头插法插入元素

        关于HashMap可能会问到的问题：
          1. HashMap, ConcurrentHashMap,HashTable 的结构，在JDK 1.7 和1.8 中有什么不同（最基础）
          2. put时，是加到链表头还是链表尾
                JDK1.8的put采用尾插法，实际调用的是putVal方法(该方法是个final方法，并没有提供给用户使用)
                JDK1.8的put采用头插法
                实质：插入操作过程的区别
          3. get的时间复杂度（对链表，对红黑树）



